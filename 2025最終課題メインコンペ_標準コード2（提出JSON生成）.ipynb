{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "lcWCr0V9vqIE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e1860c0d63045c1bf632456223581e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_440fb11d00ed4715834df52af2d566e3"
          }
        },
        "2e01f02b199d43fdb0d49e229291ec19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc209b8004f649569176af33a7d9276b",
            "placeholder": "​",
            "style": "IPY_MODEL_206a7171dce34d33a71cf93d94fef6a0",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "a5a71b5d9354429da2dc09a1f75a9896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_2e0d80c630844e8fb05fad090111b4b2",
            "placeholder": "​",
            "style": "IPY_MODEL_e2842b9b0cc6439fb5606cd6509f5cd4",
            "value": ""
          }
        },
        "1e82cd25ff2e40e3b7560c8c67df1b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_4474f2a198244ae6800af4dcb1e9c5e8",
            "style": "IPY_MODEL_94e1ddf204a8498abd984ff5646a08b0",
            "value": true
          }
        },
        "6368d703fa804100bb4013bd9b7ccf95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4759d23fb7e84a7080843499e02ff119",
            "style": "IPY_MODEL_dfc7873de4eb4a138177580afd2849aa",
            "tooltip": ""
          }
        },
        "ad36c784f6854cc4ab455371082fdbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78abe36235ca49488005eb8895a4af57",
            "placeholder": "​",
            "style": "IPY_MODEL_c7c278dff0b043e093604b2012a124a7",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "440fb11d00ed4715834df52af2d566e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "dc209b8004f649569176af33a7d9276b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "206a7171dce34d33a71cf93d94fef6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e0d80c630844e8fb05fad090111b4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2842b9b0cc6439fb5606cd6509f5cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4474f2a198244ae6800af4dcb1e9c5e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e1ddf204a8498abd984ff5646a08b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4759d23fb7e84a7080843499e02ff119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc7873de4eb4a138177580afd2849aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "78abe36235ca49488005eb8895a4af57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c278dff0b043e093604b2012a124a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bac73d0e183045b685f8727fbd1e5e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af31b614d1444b4abeca968d7f603979",
            "placeholder": "​",
            "style": "IPY_MODEL_e5affaadac7b4f698c3736adadf1ea1e",
            "value": "Connecting..."
          }
        },
        "af31b614d1444b4abeca968d7f603979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5affaadac7b4f698c3736adadf1ea1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "604d759a6f6d4654ba04e09e80d71306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_298d3360fb9e4d359ce42804acaf402c",
              "IPY_MODEL_516959d56cf2416781102e22ea8cbb49",
              "IPY_MODEL_ad68d10e4056422399785973dcd59d18"
            ],
            "layout": "IPY_MODEL_f4ef03b6737c4d8c86031507dca7cecd"
          }
        },
        "298d3360fb9e4d359ce42804acaf402c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8977b70d681443da430e33ac1c19161",
            "placeholder": "​",
            "style": "IPY_MODEL_0247e8222cc7403d9220cdf48d5040a4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "516959d56cf2416781102e22ea8cbb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c45d9c6ee8447a1a852125c6b8ac638",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_034167d89cb24cdd8da0e7b189e042c1",
            "value": 3
          }
        },
        "ad68d10e4056422399785973dcd59d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b390d06557042f4ba36395a97a076a0",
            "placeholder": "​",
            "style": "IPY_MODEL_1f8c593d83f4436c8dd775e6d4117408",
            "value": " 3/3 [00:32&lt;00:00,  8.79s/it]"
          }
        },
        "f4ef03b6737c4d8c86031507dca7cecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8977b70d681443da430e33ac1c19161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0247e8222cc7403d9220cdf48d5040a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c45d9c6ee8447a1a852125c6b8ac638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034167d89cb24cdd8da0e7b189e042c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b390d06557042f4ba36395a97a076a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8c593d83f4436c8dd775e6d4117408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7324c16fdd6e4ab7b3a8ba64fbf88e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21198f5bc68b4ec1a0b9520a4f0e7a63",
              "IPY_MODEL_cbf39b5228ba42daa7e6418d387a9b8e",
              "IPY_MODEL_bba15e95db1745d4b71b6515706feec3"
            ],
            "layout": "IPY_MODEL_1351837216b64519b4a61fa70fc9a880"
          }
        },
        "21198f5bc68b4ec1a0b9520a4f0e7a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28d3fa9570694befabfc5b8b36d592f1",
            "placeholder": "​",
            "style": "IPY_MODEL_0994c75f1f614ba693a9103f2e1f1f1a",
            "value": "Adding requests: 100%"
          }
        },
        "cbf39b5228ba42daa7e6418d387a9b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35eea056100d40ea8532de13a09202f8",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cca913f31a540748086a2dfa2e0ec0d",
            "value": 150
          }
        },
        "bba15e95db1745d4b71b6515706feec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3abd6162a50f47bbb2cad9a1650ba7d9",
            "placeholder": "​",
            "style": "IPY_MODEL_5833df02497040dfa89259a9aa1f2d18",
            "value": " 150/150 [00:00&lt;00:00, 453.72it/s]"
          }
        },
        "1351837216b64519b4a61fa70fc9a880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28d3fa9570694befabfc5b8b36d592f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0994c75f1f614ba693a9103f2e1f1f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35eea056100d40ea8532de13a09202f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cca913f31a540748086a2dfa2e0ec0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3abd6162a50f47bbb2cad9a1650ba7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5833df02497040dfa89259a9aa1f2d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "facb037baa3c4a17b26d99d46e3e9140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ee1b33bcb72420994b8283f0bd583d0",
              "IPY_MODEL_b3ae43a314544ad89954782e1f27a420",
              "IPY_MODEL_e35431b51b00411f91e0cb80f038d558"
            ],
            "layout": "IPY_MODEL_d0da64598cac45079ab47f55e77d46fe"
          }
        },
        "4ee1b33bcb72420994b8283f0bd583d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98c2b634efb46af816f4f3d6ceba211",
            "placeholder": "​",
            "style": "IPY_MODEL_94a1e017c7554832a9415ea18e80756d",
            "value": "Processed prompts: 100%"
          }
        },
        "b3ae43a314544ad89954782e1f27a420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24090d57633c44518268e35bc9a5793b",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f55eb5b21ff450e936ade9188bc4c04",
            "value": 150
          }
        },
        "e35431b51b00411f91e0cb80f038d558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e757c3c982e449abfcd67d5e5dd6ff0",
            "placeholder": "​",
            "style": "IPY_MODEL_651325be7c2b432a9a27ce43dd5bd40e",
            "value": " 150/150 [05:11&lt;00:00,  1.68s/it, est. speed input: 165.72 toks/s, output: 132.75 toks/s]"
          }
        },
        "d0da64598cac45079ab47f55e77d46fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d98c2b634efb46af816f4f3d6ceba211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a1e017c7554832a9415ea18e80756d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24090d57633c44518268e35bc9a5793b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f55eb5b21ff450e936ade9188bc4c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e757c3c982e449abfcd67d5e5dd6ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651325be7c2b432a9a27ce43dd5bd40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hirojie5310/beautiful_soup/blob/main/2025%E6%9C%80%E7%B5%82%E8%AA%B2%E9%A1%8C%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%B3%E3%83%B3%E3%83%98%E3%82%9A_%E6%A8%99%E6%BA%96%E3%82%B3%E3%83%BC%E3%83%88%E3%82%992%EF%BC%88%E6%8F%90%E5%87%BAJSON%E7%94%9F%E6%88%90%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 最終課題（メインコンペ） 推論標準コード\n",
        "\n",
        "## 1.概要\n",
        "このノートブックは、あなたが学習して Hugging Face にアップした **LoRAアダプタ**を用いて、  \n",
        "**ベンチマークの推論結果JSONを生成し、コンペの提出用JSONファイルを生成する**ための標準コードです。\n",
        "- コンペでの提出物は **学習済みLoRAそのものではなく、推論結果のJSONファイル**です。  \n",
        "- 本ノートは、その提出用JSONを確実に作るための手順を提供します。\n",
        "\n",
        "- StructEval-Tからサンプリングした150問の回答を生成（推論）します。\n",
        "- 実行にあたっては、/content/public_150.json（配布資料）が必要です。\n",
        "- 出力は**inference.json（提出形式）**ですので、これをOmniCampusにアップロードして採点してください。"
      ],
      "metadata": {
        "id": "Yo1rCsGugXIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 事前準備"
      ],
      "metadata": {
        "id": "i86bwRT4iM1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Colab のランタイムを **GPU（T4）** に設定してください。\n",
        "- Hugging Face にログインします（トークン入力が必要です）。\n",
        "- 推論に使う LoRA アダプタは、原則として「学習ノートでアップロードしたもの」を使用します。\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "P69owhiqiM3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 3. 実行手順（推奨フロー）\n"
      ],
      "metadata": {
        "id": "kK0KGIY3iM8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 0: セットアップ（clone / install）\n",
        "上から順にセルを実行します。\n",
        "\n",
        "- `StructEval` を clone し、依存関係（vLLM等）を導入します。\n",
        "- `python3 -m structeval.cli --help` が表示されれば、基本セットアップは成功です。\n",
        "\n",
        "### Step 1: Hugging Face ログイン\n",
        "- `login()` を実行し、トークンを入力してください。\n",
        "\n",
        "### Step 2: LoRA の統合（merge）\n",
        "- `adapter_id` にある LoRA を読み込み、ベースモデルと統合して `./merged_model` を生成します。\n",
        "- ここが完了すると、以降の推論は **`./merged_model` をモデルパスとして使用**します。\n",
        "\n",
        "### Step 3: vLLM 推論の実行と提出用JSONの生成\n",
        "- `custom_inference.py` が生成され、それを実行します。\n",
        "- 推論結果は `/content/StructEval/outputs/nonrenderable.json` に保存されます。\n",
        "- `output` を `generation` に補完し、提出用ファイル `/content/inference.json` を出力します。\n",
        "- 出力された`/content/inference.json` をダウンロードして、Omnicampusに提出してください。\n",
        "---"
      ],
      "metadata": {
        "id": "awzqJJPIiM-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 4. 出力ファイル（提出物）の扱い\n"
      ],
      "metadata": {
        "id": "CnpX8ZJ7gzrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4.1 生成される主なファイル\n",
        "- 統合済みモデル（提出不要）\n",
        "  - `./merged_model/`\n",
        "\n",
        "- 推論結果 **提出用ファイル（最重要）**\n",
        "  - `/content/inference.json`\n",
        "  - ※このファイルは `generation` フィールドを持つ形式に整形済みです。\n",
        "\n",
        "### 4.2 提出手順（ダウンロード → Omnicampus にアップロード）\n",
        "1. Colab 上で、最終成果物 `/content/inference.json` をローカルPCに **ダウンロード**します。\n",
        "   - Colab 左の「Files（フォルダアイコン）」から `/content/` を開く\n",
        "   - `inference.json` を右クリック → **Download**\n",
        "\n",
        "2. Omnicampus の提出画面で、ダウンロードした `inference.json` を **アップロードして提出**します。\n",
        "\n",
        "提出ファイル名は、`inference.json` としてください。\n",
        "\n",
        "\n",
        "### **4.3 コンペ参加における注意点**：\n",
        "- 本コードによる推論には「学習してアップしたLoRA」を使ってください。それ以外のモデルを使った推論結果を提出した方は、失格となります。\n",
        "- 提出物は「推論結果 JSON」です（LoRA自体の提出ではありません）。\n",
        "- 提出の際に、HuggingFaceにアップしたアダプタのURLを必ず記載してください。\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Dzu1fQyiiyL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. よくある失敗と対策\n"
      ],
      "metadata": {
        "id": "YBkvMWDCiyO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **GPUが有効になっていない**\n",
        "  - 推論が極端に遅い／vLLMが動かない原因になります。必ず T4 を確認してください。\n",
        "\n",
        "- **`./merged_model` が存在しない**\n",
        "  - LoRA統合（merge）が完了していない可能性があります。mergeセルを再実行してください。\n",
        "\n",
        "- **vLLM 実行時に OOM（Out of Memory）になる**\n",
        "  - 本標準コードは `gpu_memory_utilization=0.6` で安全寄りですが、環境差で落ちる場合があります。\n",
        "  - その場合は、まずランタイム再起動（Factory reset）→同じ手順で再実行してください。\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "KDHi4u0ggztj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 6. 期待する最終状態（チェック）\n"
      ],
      "metadata": {
        "id": "uGKq9afckmbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "提出直前に、次を満たしていればOKです。\n",
        "\n",
        "- `/content/inference.json` が存在する\n",
        "- そのJSONが list であり、各要素に `generation` フィールドが入っている（空でない）\n",
        "- Omnicampus に `inference.json` をアップロードして提出\n",
        "---\n"
      ],
      "metadata": {
        "id": "zMcE5FIVkmd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実行コード"
      ],
      "metadata": {
        "id": "2LAE32yBP4Pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 0: セットアップ（clone / install）"
      ],
      "metadata": {
        "id": "WJ8okWTTviHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Setup (バージョン固定)\n",
        "\n",
        "!git clone -b fix-module-not-found-issue-2 https://github.com/Osakana7777777/StructEval.git\n",
        "\n",
        "!uv pip install \\\n",
        "  \"vllm==0.13.0\" \\\n",
        "  \"torch==2.9.0\" \\\n",
        "  \"torchaudio==2.9.0\" \\\n",
        "  \"torchvision==0.24.0\" \\\n",
        "  \"triton==3.5.0\" \\\n",
        "  \"compressed-tensors==0.12.2\" \\\n",
        "  \"openai==2.15.0\" \\\n",
        "  \"xgrammar==0.1.27\" \\\n",
        "  \"bitsandbytes==0.46.1\" \\\n",
        "  fire\n",
        "\n",
        "# flash-attn だけは環境によって挙動が変わるためバージョン固定しない\n",
        "!uv pip install flash-attn --no-build-isolation\n",
        "\n",
        "%cd StructEval\n",
        "!uv pip install -e .\n",
        "\n",
        "!python3 -m structeval.cli --help\n",
        "!mkdir -p outputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGIUuwBZz9-o",
        "outputId": "fb5a1a52-aea8-46bd-92f4-52bbd643e31f",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'StructEval'...\n",
            "remote: Enumerating objects: 17398, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 17398 (delta 91), reused 45 (delta 26), pack-reused 17249 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17398/17398), 529.90 MiB | 17.06 MiB/s, done.\n",
            "Resolving deltas: 100% (5424/5424), done.\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m165 packages\u001b[0m \u001b[2min 892ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m50 packages\u001b[0m \u001b[2min 17.04s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m7 packages\u001b[0m \u001b[2min 741ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m50 packages\u001b[0m \u001b[2min 246ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manthropic\u001b[0m\u001b[2m==0.71.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mapache-tvm-ffi\u001b[0m\u001b[2m==0.1.8.post2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mastor\u001b[0m\u001b[2m==0.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.46.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcbor2\u001b[0m\u001b[2m==5.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcompressed-tensors\u001b[0m\u001b[2m==0.12.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdepyf\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdnspython\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1memail-validator\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastapi-cli\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastapi-cloud-cli\u001b[0m\u001b[2m==0.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastar\u001b[0m\u001b[2m==0.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfire\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflashinfer-python\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mijson\u001b[0m\u001b[2m==3.4.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1minteregular\u001b[0m\u001b[2m==0.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjmespath\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllguidance\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.43.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlm-format-enforcer\u001b[0m\u001b[2m==0.11.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmistral-common\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmodel-hosting-container-standards\u001b[0m\u001b[2m==0.1.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mninja\u001b[0m\u001b[2m==1.13.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.60.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-frontend\u001b[0m\u001b[2m==1.18.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cutlass-dsl\u001b[0m\u001b[2m==4.3.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==2.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==2.15.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopenai-harmony\u001b[0m\u001b[2m==0.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moutlines-core\u001b[0m\u001b[2m==0.2.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpartial-json-parser\u001b[0m\u001b[2m==0.2.1.1.post7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprometheus-fastapi-instrumentator\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpycountry\u001b[0m\u001b[2m==24.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-extra-types\u001b[0m\u001b[2m==2.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mray\u001b[0m\u001b[2m==2.53.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrich-toolkit\u001b[0m\u001b[2m==0.18.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrignore\u001b[0m\u001b[2m==0.7.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetproctitle\u001b[0m\u001b[2m==1.3.7\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==75.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.10.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msupervisor\u001b[0m\u001b[2m==4.3.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==5.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mvllm\u001b[0m\u001b[2m==0.13.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxgrammar\u001b[0m\u001b[2m==0.1.27\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m28 packages\u001b[0m \u001b[2min 1.10s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 19.06s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflash-attn\u001b[0m\u001b[2m==2.8.3\u001b[0m\n",
            "/content/StructEval\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m235 packages\u001b[0m \u001b[2min 2.27s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m38 packages\u001b[0m \u001b[2min 1.15s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m11 packages\u001b[0m \u001b[2min 37ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m38 packages\u001b[0m \u001b[2min 52ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiodns\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masyncstdlib-fw\u001b[0m\u001b[2m==3.13.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==23.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbackports-zstd\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbetterproto-fw\u001b[0m\u001b[2m==2.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mblack\u001b[0m\u001b[2m==25.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdotenv\u001b[0m\u001b[2m==0.9.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1meval-type-backport\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfireworks-ai\u001b[0m\u001b[2m==0.19.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpx-ws\u001b[0m\u001b[2m==0.8.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1micecream\u001b[0m\u001b[2m==2.1.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1minvoke\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllm-engines\u001b[0m\u001b[2m==0.0.25\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmistralai\u001b[0m\u001b[2m==1.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-common\u001b[0m\u001b[2m==1.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-common\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-http\u001b[0m\u001b[2m==1.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-http\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopentelemetry-proto\u001b[0m\u001b[2m==1.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-proto\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.38.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.58b0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.59b0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpathspec\u001b[0m\u001b[2m==1.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpdf2image\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplaywright\u001b[0m\u001b[2m==1.58.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==5.29.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==5.29.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpycares\u001b[0m\u001b[2m==5.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyee\u001b[0m\u001b[2m==13.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytokens\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==13.9.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.3.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.14.14\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.9.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstructeval\u001b[0m\u001b[2m==0.0.5 (from file:///content/StructEval)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtogether\u001b[0m\u001b[2m==1.5.35\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwsproto\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxmltodict\u001b[0m\u001b[2m==1.0.2\u001b[0m\n",
            "INFO: Showing help with the command 'cli.py -- --help'.\n",
            "\n",
            "\u001b[1mNAME\u001b[0m\n",
            "    cli.py\n",
            "\n",
            "\u001b[1mSYNOPSIS\u001b[0m\n",
            "    cli.py -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 1: Hugging Face ログイン\n",
        "- `login()` を実行し、トークンを入力してください。\n"
      ],
      "metadata": {
        "id": "lcWCr0V9vqIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# 1) HF login (once)\n",
        "# -----------------------------\n",
        "# HF Hub上のデータセットを読むため、HuggingFaceにログインします。\n",
        "#\n",
        "from huggingface_hub import login\n",
        "login()  # Colab will prompt"
      ],
      "metadata": {
        "id": "SrjUvUoPP6i9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "1e1860c0d63045c1bf632456223581e0",
            "2e01f02b199d43fdb0d49e229291ec19",
            "a5a71b5d9354429da2dc09a1f75a9896",
            "1e82cd25ff2e40e3b7560c8c67df1b4a",
            "6368d703fa804100bb4013bd9b7ccf95",
            "ad36c784f6854cc4ab455371082fdbbb",
            "440fb11d00ed4715834df52af2d566e3",
            "dc209b8004f649569176af33a7d9276b",
            "206a7171dce34d33a71cf93d94fef6a0",
            "2e0d80c630844e8fb05fad090111b4b2",
            "e2842b9b0cc6439fb5606cd6509f5cd4",
            "4474f2a198244ae6800af4dcb1e9c5e8",
            "94e1ddf204a8498abd984ff5646a08b0",
            "4759d23fb7e84a7080843499e02ff119",
            "dfc7873de4eb4a138177580afd2849aa",
            "78abe36235ca49488005eb8895a4af57",
            "c7c278dff0b043e093604b2012a124a7",
            "bac73d0e183045b685f8727fbd1e5e9e",
            "af31b614d1444b4abeca968d7f603979",
            "e5affaadac7b4f698c3736adadf1ea1e"
          ]
        },
        "outputId": "a97c23f5-50f6-4a32-d289-657969c714ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e1860c0d63045c1bf632456223581e0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 2: LoRA の統合（merge）\n",
        "- `adapter_id` にある LoRA を読み込み、ベースモデルと統合して `./merged_model` を生成します。\n",
        "- ここが完了すると、以降の推論は **`./merged_model` をモデルパスとして使用**します。\n",
        "\n"
      ],
      "metadata": {
        "id": "P8fExEKkwEtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ここで、contentフォルダに\"public_150.json\"をアップロードしてください。\n",
        "- Colabのファイル領域(/content)に、評価用の public_150.json を置く必要があります。"
      ],
      "metadata": {
        "id": "xTCIiMYqe87c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 1) Config\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "MODEL_SOURCE = \"adapter_merge\"   # \"merged\" | \"base\" | \"adapter_merge\"\n",
        "# どのモデルを使うかを選びます。今回は、基本的に\"adapter_merge\"を選んでください。\n",
        "\n",
        "#   - \"base\"        : ベースモデル（学習していない素のモデル）\n",
        "#   - \"merged\"      : すでにLoRAをマージ済みのモデル（完成品として配布されている想定）\n",
        "#   - \"adapter_merge\": ベースモデル + LoRAアダプタをその場で読み込み、ローカルでマージしてから使う\n",
        "\n",
        "# base model (HF repo id or local path)\n",
        "# 学習時に使用したベースモデルを入れてください。\n",
        "BASE_MODEL_ID_OR_PATH   = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "\n",
        "# merged model (HF repo id or local path)\n",
        "# アダプタではなくマージモデルをアップロードした場合は、ここにIDをいれてください。\n",
        "# \"merged\"を選択した場合に記入\n",
        "MERGED_MODEL_ID_OR_PATH = \"your_id/your-merged-repo\"\n",
        "\n",
        "# adapter merge\n",
        "# あなたがHuggingFaceにアップロードしたアダプタのIDを入れてください。\n",
        "# \"adapter_merge\"を選択した場合に記入\n",
        "ADAPTER_ID       = \"Hirojie5310/your-lora-repo\"\n",
        "\n",
        "# merge済モデルの一時保存\n",
        "MERGED_LOCAL_DIR = \"./merged_model\"\n",
        "\n",
        "# 入力（150問）と出力（提出用）ファイルパスの指定\n",
        "INPUT_PATH  = \"/content/public_150.json\"\n",
        "OUTPUT_PATH = \"/content/inference.json\"\n",
        "\n",
        "\n",
        "TEMPERATURE = 0.0\n",
        "#   0.0 は最も決定的（同じ入力なら同じ出力になりやすい）で、評価用途では一般に安定します。\n"
      ],
      "metadata": {
        "id": "5_F2mbjIwRoE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: vLLM 推論の実行と提出用JSONの生成\n",
        "- `custom_inference.py` が生成され、それを実行します。\n",
        "- 推論結果は `/content/StructEval/outputs/nonrenderable.json` に保存されます。\n",
        "- `output` を `generation` に補完し、提出用ファイル `/content/inference.json` を出力します。\n",
        "- 出力された`/content/inference.json` をダウンロードして、Omnicampusに提出してください。\n",
        "---"
      ],
      "metadata": {
        "id": "-O-8HtLKwRx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Stable vLLM env (IMPORTANT: must be set BEFORE importing vllm)\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "os.environ[\"VLLM_WORKER_MULTIPROC_METHOD\"] = \"spawn\"\n",
        "# vLLM内部でワーカープロセスを作る方式を \"spawn\" に固定します。\n",
        "# Colabなど一部環境では \"fork\" より安定しやすいことがあります。\n",
        "\n",
        "os.environ[\"VLLM_LOGGING_LEVEL\"] = \"INFO\"\n",
        "# vLLMのログレベル（INFO）を設定します。デバッグ時に有用です。\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Resolve model_path\n",
        "# ------------------------------------------------------------\n",
        "# 選んだMODEL_SOURCEに応じて、最終的にvLLMに渡す「モデルの場所(model_path)」を決めます。\n",
        "\n",
        "def resolve_model_path():\n",
        "    # どのモデルを使うかに応じて、vLLMへ渡すパス/IDを返す関数\n",
        "\n",
        "    if MODEL_SOURCE == \"base\":\n",
        "        return BASE_MODEL_ID_OR_PATH\n",
        "\n",
        "    if MODEL_SOURCE == \"merged\":\n",
        "        return MERGED_MODEL_ID_OR_PATH\n",
        "\n",
        "    if MODEL_SOURCE == \"adapter_merge\":\n",
        "        # NOTE: torch/CUDA（GPU）を触るため、vLLMを起動する前に済ませます。\n",
        "        import os, gc\n",
        "        import torch\n",
        "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "        from peft import PeftModel\n",
        "        print(\"[INFO] Merging adapter into base model...\")\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            BASE_MODEL_ID_OR_PATH,\n",
        "            dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "        )\n",
        "        # ベースモデルに対応するトークナイザを読み込み（マージ後も同じものを使うのが通常）\n",
        "        tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID_OR_PATH, trust_remote_code=True)\n",
        "\n",
        "        # base_model に LoRAアダプタ(ADAPTER_ID) をマージ\n",
        "        # merge後はLoRA層を外せるので（unload）、推論時の扱いが単純になります。\n",
        "        model_to_merge = PeftModel.from_pretrained(base_model, ADAPTER_ID)\n",
        "        merged_model = model_to_merge.merge_and_unload()\n",
        "\n",
        "        os.makedirs(MERGED_LOCAL_DIR, exist_ok=True)\n",
        "        merged_model.save_pretrained(MERGED_LOCAL_DIR)\n",
        "        tokenizer.save_pretrained(MERGED_LOCAL_DIR)\n",
        "\n",
        "        del base_model, model_to_merge, merged_model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"[INFO] Merged model saved:\", MERGED_LOCAL_DIR)\n",
        "        return MERGED_LOCAL_DIR\n",
        "\n",
        "    raise ValueError(\"MODEL_SOURCE must be 'merged'|'base'|'adapter_merge'\")\n",
        "\n",
        "# 最終的に使うモデルのパス/IDを確定\n",
        "model_path = resolve_model_path()\n",
        "print(\"[INFO] Using model:\", model_path)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Load public_150 and build prompts (no torch usage here)\n",
        "# ------------------------------------------------------------\n",
        "# 入力ファイルを読み込み、各問題の「プロンプト（モデルに渡す文字列）」を作ります。\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "pub = json.loads(Path(INPUT_PATH).read_text(encoding=\"utf-8\"))\n",
        "\n",
        "assert isinstance(pub, list), \"public_150.json must be a list\"\n",
        "assert len(pub) == 150, f\"public_150 must have 150 items, got {len(pub)}\"\n",
        "assert len({x[\"task_id\"] for x in pub}) == 150, \"public_150 has duplicate task_id\"\n",
        "\n",
        "# Safety: ensure output_type exists (office enriched file)\n",
        "\n",
        "missing_ot = [x.get(\"task_id\") for x in pub if not (x.get(\"output_type\") or \"\").strip()]\n",
        "\n",
        "if missing_ot:\n",
        "    raise RuntimeError(f\"FATAL: public_150 missing output_type (not enriched). Examples: {missing_ot[:5]}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
        "\n",
        "# task_ids: 出力に使う task_id の並びを保存\n",
        "# prompts:   vLLMに渡すプロンプト文字列を保存\n",
        "task_ids, prompts = [], []\n",
        "\n",
        "for item in pub:\n",
        "    task_ids.append(item[\"task_id\"])\n",
        "    query = item.get(\"query\", \"\")\n",
        "    messages = [{\"role\": \"user\", \"content\": query}]\n",
        "    prompts.append(tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True))\n",
        "    # ↑ apply_chat_template で「モデルが期待する会話形式の文字列」に整形\n",
        "    #   tokenize=False : まだトークン化せず、文字列として返す\n",
        "    #   add_generation_prompt=True : 「ここからアシスタントが答える」境界を追加\n",
        "    #   これにより、モデルが回答を続けて生成しやすい形になります。\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Presets + fallback plan\n",
        "# ------------------------------------------------------------\n",
        "# vLLM起動時に「文脈長(max_model_len)」や「出力上限(max_tokens)」を大きくしすぎると、\n",
        "# GPUメモリ不足(OOM)で落ちやすいです。\n",
        "# そこで、成功しやすい設定をいくつか用意し、失敗したら段階的に軽くして再試行します。\n",
        "# merged（既に焼き込み済み）と adapter_merge（その場でマージ）では、\n",
        "# 実メモリ使用量が変わることがあるため、最初に試す設定（gpu_memなど）を変えています。\n",
        "# 事前に「試行候補リスト」を作り、上から順に試します。\n",
        "\n",
        "def build_try_configs():\n",
        "\n",
        "    # Primary presets\n",
        "\n",
        "    if MODEL_SOURCE == \"merged\":\n",
        "        base = [\n",
        "            {\"max_model_len\": 4096, \"max_tokens\": 4096, \"gpu_mem\": 0.85},\n",
        "            {\"max_model_len\": 4096, \"max_tokens\": 4096, \"gpu_mem\": 0.80},\n",
        "        ]\n",
        "        # ↑ 4096トークンまでの文脈/出力を許しつつ、GPU使用率を0.85→0.80で試す\n",
        "\n",
        "    elif MODEL_SOURCE == \"adapter_merge\":\n",
        "        base = [\n",
        "            {\"max_model_len\": 4096, \"max_tokens\": 4096, \"gpu_mem\": 0.60},\n",
        "            {\"max_model_len\": 4096, \"max_tokens\": 4096, \"gpu_mem\": 0.65},\n",
        "        ]\n",
        "        # ↑ adapter_merge はメモリが厳しくなりがちなので、gpu_memを低めから試します。\n",
        "\n",
        "    else:  # base\n",
        "        base = [\n",
        "            {\"max_model_len\": 4096, \"max_tokens\": 4096, \"gpu_mem\": 0.80},\n",
        "            {\"max_model_len\": 4096, \"max_tokens\": 4096, \"gpu_mem\": 0.70},\n",
        "        ]\n",
        "        # ↑ baseモデルは比較的軽い想定で、0.80→0.70を試します。\n",
        "\n",
        "    # Fallback ladder (reduce context / output)\n",
        "    # 失敗したときの「段階的に軽くする設定」。\n",
        "    # max_model_len と max_tokens を下げると、必要メモリが減り成功しやすくなります。\n",
        "    ladder = [\n",
        "        {\"max_model_len\": 3072, \"max_tokens\": 3072},\n",
        "        {\"max_model_len\": 2048, \"max_tokens\": 2048},\n",
        "        {\"max_model_len\": 1536, \"max_tokens\": 1536},\n",
        "    ]\n",
        "\n",
        "    # Expand base configs with ladder and a couple gpu_mem tweaks\n",
        "    # ↑ base設定に対し、ladder段階を「合成」して試行パターンを増やします。\n",
        "    #   また、gpu_memも少し増やす版を試します（失敗理由が「確保不足」系のときに効く場合がある）。\n",
        "    out = []\n",
        "    for cfg in base:\n",
        "        out.append(cfg)\n",
        "\n",
        "        for step in ladder:\n",
        "            out.append({**cfg, **step})\n",
        "\n",
        "        # try a slightly higher gpu_mem if still failing (some failures are \"not enough alloc\")\n",
        "        out.append({**cfg, \"gpu_mem\": min(0.90, cfg[\"gpu_mem\"] + 0.05)})\n",
        "\n",
        "    # Deduplicate while preserving order\n",
        "    # ↑ 似た設定が重複し得るので、順序を保ったまま重複削除します。\n",
        "    seen = set()\n",
        "    uniq = []\n",
        "    for c in out:\n",
        "        key = (c[\"max_model_len\"], c[\"max_tokens\"], round(c[\"gpu_mem\"], 2))\n",
        "\n",
        "        if key in seen:\n",
        "            continue\n",
        "\n",
        "        seen.add(key)\n",
        "        uniq.append(c)\n",
        "\n",
        "    return uniq\n",
        "\n",
        "\n",
        "TRY_CONFIGS = build_try_configs()\n",
        "# ↑ 実際に試す設定リストを作成します。\n",
        "\n",
        "print(\"[INFO] Try configs (in order):\")\n",
        "\n",
        "for i, c in enumerate(TRY_CONFIGS[:8], 1):\n",
        "    print(f\"  {i:02d}. max_model_len={c['max_model_len']} max_tokens={c['max_tokens']} gpu_mem={c['gpu_mem']}\")\n",
        "\n",
        "if len(TRY_CONFIGS) > 8:\n",
        "    print(f\"  ... total {len(TRY_CONFIGS)} configs\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6) vLLM run with retry\n",
        "# ------------------------------------------------------------\n",
        "# ↑ ここからが推論本体です。\n",
        "\n",
        "from vllm import LLM, SamplingParams\n",
        "def run_with_config(cfg):\n",
        "\n",
        "    sampling = SamplingParams(\n",
        "        temperature=TEMPERATURE,\n",
        "        max_tokens=cfg[\"max_tokens\"],\n",
        "    )\n",
        "\n",
        "    llm = LLM(\n",
        "        model=model_path,\n",
        "        max_model_len=cfg[\"max_model_len\"],\n",
        "        gpu_memory_utilization=cfg[\"gpu_mem\"],\n",
        "        enforce_eager=True,\n",
        "        tensor_parallel_size=1,\n",
        "         disable_log_stats=True,\n",
        "    )\n",
        "\n",
        "    outs = llm.generate(prompts, sampling)\n",
        "\n",
        "    submission = []\n",
        "    # ↑ 提出形式 [{\"task_id\": ..., \"generation\": ...}, ...] を作ります。\n",
        "\n",
        "    for tid, out in zip(task_ids, outs):\n",
        "        gen = out.outputs[0].text if out.outputs else \"\"\n",
        "        submission.append({\"task_id\": tid, \"generation\": gen})\n",
        "    return submission\n",
        "    # ↑ 150問ぶんの提出配列を返します。\n",
        "\n",
        "last_err = None\n",
        "submission = None\n",
        "# ↑ 成功した場合に提出データ（150件）を入れる変数。成功まではNone。\n",
        "\n",
        "for idx, cfg in enumerate(TRY_CONFIGS, 1):\n",
        "    print(f\"[INFO] Attempt {idx}/{len(TRY_CONFIGS)}: max_model_len={cfg['max_model_len']} max_tokens={cfg['max_tokens']} gpu_mem={cfg['gpu_mem']}\")\n",
        "    try:\n",
        "        submission = run_with_config(cfg)\n",
        "        print(\"[INFO] ✅ Generation succeeded with this config.\")\n",
        "        # ↑ 成功ログ\n",
        "        break\n",
        "    except RuntimeError as e:\n",
        "        last_err = e\n",
        "        msg = str(e)\n",
        "        print(\"[WARN] Failed:\", msg[:200].replace(\"\\n\", \" \"))\n",
        "\n",
        "# try next config\n",
        "if submission is None:\n",
        "    raise RuntimeError(f\"All configs failed. Last error: {last_err}\")\n",
        "\n",
        "\n",
        "# Final guards\n",
        "# ↑ 最後に「提出物としての整合性チェック」をします。\n",
        "\n",
        "if len(submission) != 150:\n",
        "    # ↑ 150件生成できているかチェック\n",
        "    raise RuntimeError(f\"Submission count mismatch: {len(submission)}\")\n",
        "\n",
        "if len({x['task_id'] for x in submission}) != 150:\n",
        "    # ↑ task_id の重複がないかチェック\n",
        "    raise RuntimeError(\"Duplicate task_id in submission\")\n",
        "\n",
        "Path(OUTPUT_PATH).write_text(json.dumps(submission, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "# ↑ submission（Pythonオブジェクト）をJSON文字列にしてファイルへ保存します。\n",
        "\n",
        "print(\"[OK] wrote:\", OUTPUT_PATH, \"items=150\")\n"
      ],
      "metadata": {
        "id": "rCbWE8H6qDeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "604d759a6f6d4654ba04e09e80d71306",
            "298d3360fb9e4d359ce42804acaf402c",
            "516959d56cf2416781102e22ea8cbb49",
            "ad68d10e4056422399785973dcd59d18",
            "f4ef03b6737c4d8c86031507dca7cecd",
            "f8977b70d681443da430e33ac1c19161",
            "0247e8222cc7403d9220cdf48d5040a4",
            "3c45d9c6ee8447a1a852125c6b8ac638",
            "034167d89cb24cdd8da0e7b189e042c1",
            "6b390d06557042f4ba36395a97a076a0",
            "1f8c593d83f4436c8dd775e6d4117408",
            "7324c16fdd6e4ab7b3a8ba64fbf88e3f",
            "21198f5bc68b4ec1a0b9520a4f0e7a63",
            "cbf39b5228ba42daa7e6418d387a9b8e",
            "bba15e95db1745d4b71b6515706feec3",
            "1351837216b64519b4a61fa70fc9a880",
            "28d3fa9570694befabfc5b8b36d592f1",
            "0994c75f1f614ba693a9103f2e1f1f1a",
            "35eea056100d40ea8532de13a09202f8",
            "4cca913f31a540748086a2dfa2e0ec0d",
            "3abd6162a50f47bbb2cad9a1650ba7d9",
            "5833df02497040dfa89259a9aa1f2d18",
            "facb037baa3c4a17b26d99d46e3e9140",
            "4ee1b33bcb72420994b8283f0bd583d0",
            "b3ae43a314544ad89954782e1f27a420",
            "e35431b51b00411f91e0cb80f038d558",
            "d0da64598cac45079ab47f55e77d46fe",
            "d98c2b634efb46af816f4f3d6ceba211",
            "94a1e017c7554832a9415ea18e80756d",
            "24090d57633c44518268e35bc9a5793b",
            "5f55eb5b21ff450e936ade9188bc4c04",
            "0e757c3c982e449abfcd67d5e5dd6ff0",
            "651325be7c2b432a9a27ce43dd5bd40e"
          ]
        },
        "outputId": "976ddf20-84d7-4f84-afb9-9ecd990bb186"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Merging adapter into base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "604d759a6f6d4654ba04e09e80d71306"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Merged model saved: ./merged_model\n",
            "[INFO] Using model: ./merged_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer you are loading from './merged_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Try configs (in order):\n",
            "  01. max_model_len=4096 max_tokens=4096 gpu_mem=0.6\n",
            "  02. max_model_len=3072 max_tokens=3072 gpu_mem=0.6\n",
            "  03. max_model_len=2048 max_tokens=2048 gpu_mem=0.6\n",
            "  04. max_model_len=1536 max_tokens=1536 gpu_mem=0.6\n",
            "  05. max_model_len=4096 max_tokens=4096 gpu_mem=0.65\n",
            "  06. max_model_len=3072 max_tokens=3072 gpu_mem=0.65\n",
            "  07. max_model_len=2048 max_tokens=2048 gpu_mem=0.65\n",
            "  08. max_model_len=1536 max_tokens=1536 gpu_mem=0.65\n",
            "  ... total 9 configs\n",
            "[INFO] Attempt 1/9: max_model_len=4096 max_tokens=4096 gpu_mem=0.6\n",
            "INFO 02-04 16:03:11 [utils.py:253] non-default args: {'max_model_len': 4096, 'gpu_memory_utilization': 0.6, 'disable_log_stats': True, 'enforce_eager': True, 'model': './merged_model'}\n",
            "INFO 02-04 16:04:11 [model.py:514] Resolved architecture: Qwen3ForCausalLM\n",
            "INFO 02-04 16:04:11 [model.py:1661] Using max model len 4096\n",
            "INFO 02-04 16:04:16 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 02-04 16:04:16 [vllm.py:622] Enforce eager set, overriding optimization level to -O0\n",
            "INFO 02-04 16:04:16 [vllm.py:722] Cudagraph is disabled under eager mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer you are loading from './merged_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Failed: Engine core initialization failed. See root cause above. Failed core proc(s): {}\n",
            "[INFO] Attempt 2/9: max_model_len=3072 max_tokens=3072 gpu_mem=0.6\n",
            "INFO 02-04 16:05:17 [utils.py:253] non-default args: {'max_model_len': 3072, 'gpu_memory_utilization': 0.6, 'disable_log_stats': True, 'enforce_eager': True, 'model': './merged_model'}\n",
            "INFO 02-04 16:05:17 [model.py:514] Resolved architecture: Qwen3ForCausalLM\n",
            "INFO 02-04 16:05:17 [model.py:1661] Using max model len 3072\n",
            "INFO 02-04 16:05:17 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 02-04 16:05:17 [vllm.py:622] Enforce eager set, overriding optimization level to -O0\n",
            "INFO 02-04 16:05:17 [vllm.py:722] Cudagraph is disabled under eager mode\n",
            "[WARN] Failed: Engine core initialization failed. See root cause above. Failed core proc(s): {}\n",
            "[INFO] Attempt 3/9: max_model_len=2048 max_tokens=2048 gpu_mem=0.6\n",
            "INFO 02-04 16:06:18 [utils.py:253] non-default args: {'max_model_len': 2048, 'gpu_memory_utilization': 0.6, 'disable_log_stats': True, 'enforce_eager': True, 'model': './merged_model'}\n",
            "INFO 02-04 16:06:18 [model.py:514] Resolved architecture: Qwen3ForCausalLM\n",
            "INFO 02-04 16:06:18 [model.py:1661] Using max model len 2048\n",
            "INFO 02-04 16:06:18 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 02-04 16:06:18 [vllm.py:622] Enforce eager set, overriding optimization level to -O0\n",
            "INFO 02-04 16:06:18 [vllm.py:722] Cudagraph is disabled under eager mode\n",
            "[WARN] Failed: Engine core initialization failed. See root cause above. Failed core proc(s): {}\n",
            "[INFO] Attempt 4/9: max_model_len=1536 max_tokens=1536 gpu_mem=0.6\n",
            "INFO 02-04 16:07:19 [utils.py:253] non-default args: {'max_model_len': 1536, 'gpu_memory_utilization': 0.6, 'disable_log_stats': True, 'enforce_eager': True, 'model': './merged_model'}\n",
            "INFO 02-04 16:07:19 [model.py:514] Resolved architecture: Qwen3ForCausalLM\n",
            "INFO 02-04 16:07:19 [model.py:1661] Using max model len 1536\n",
            "INFO 02-04 16:07:20 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 02-04 16:07:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0\n",
            "INFO 02-04 16:07:20 [vllm.py:722] Cudagraph is disabled under eager mode\n",
            "[WARN] Failed: Engine core initialization failed. See root cause above. Failed core proc(s): {}\n",
            "[INFO] Attempt 5/9: max_model_len=4096 max_tokens=4096 gpu_mem=0.65\n",
            "INFO 02-04 16:08:20 [utils.py:253] non-default args: {'max_model_len': 4096, 'gpu_memory_utilization': 0.65, 'disable_log_stats': True, 'enforce_eager': True, 'model': './merged_model'}\n",
            "INFO 02-04 16:08:20 [model.py:514] Resolved architecture: Qwen3ForCausalLM\n",
            "INFO 02-04 16:08:20 [model.py:1661] Using max model len 4096\n",
            "INFO 02-04 16:08:20 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 02-04 16:08:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0\n",
            "INFO 02-04 16:08:20 [vllm.py:722] Cudagraph is disabled under eager mode\n",
            "[WARN] Failed: Engine core initialization failed. See root cause above. Failed core proc(s): {}\n",
            "[INFO] Attempt 6/9: max_model_len=3072 max_tokens=3072 gpu_mem=0.65\n",
            "INFO 02-04 16:09:21 [utils.py:253] non-default args: {'max_model_len': 3072, 'gpu_memory_utilization': 0.65, 'disable_log_stats': True, 'enforce_eager': True, 'model': './merged_model'}\n",
            "INFO 02-04 16:09:21 [model.py:514] Resolved architecture: Qwen3ForCausalLM\n",
            "INFO 02-04 16:09:21 [model.py:1661] Using max model len 3072\n",
            "INFO 02-04 16:09:21 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 02-04 16:09:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0\n",
            "INFO 02-04 16:09:21 [vllm.py:722] Cudagraph is disabled under eager mode\n",
            "INFO 02-04 16:12:53 [llm.py:360] Supported tasks: ['generate']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding requests:   0%|          | 0/150 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7324c16fdd6e4ab7b3a8ba64fbf88e3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed prompts:   0%|          | 0/150 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "facb037baa3c4a17b26d99d46e3e9140"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] ✅ Generation succeeded with this config.\n",
            "[OK] wrote: /content/inference.json items=150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sBEdgA_WJSl",
        "outputId": "dd91c9e2-e5b8-457f-fc50-4186cb58fd2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Dec  9 14:42 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 8 root root 4096 Feb  4 15:38 \u001b[01;34mStructEval\u001b[0m/\n"
          ]
        }
      ]
    }
  ]
}